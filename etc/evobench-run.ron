// More docs may be available in the evobench source code, start with
// `RunConfig` in `evobench-evaluator/src/run/config.rs`

RunConfig(
    queues: (
        // run_queues_basedir: Some("other/path/than/home/.evobench-run/queues/"),

        // List of queues each job goes through in order--each entry
        // being a tuple of subdirectory name (under
        // `~/.evobench-run/queues/` by default) and scheduling
        // configuration. Jobs are inserted (via `evobench-run
        // insert`, `evobench-run insert-local`, `evobench-run poll`)
        // into the first queue configured here, then may be moved to
        // the next, depending on the scheduling configuration.
        pipeline: [
            // Scheduling type `Immediately` means that jobs are
            // picked up ASAP, i.e. immediately after a queue that
            // started processing is finished (perhaps, once
            // implemented, immediately after the current job is
            // finished). This scheduling type does not have
            // parameters; jobs are run exactly once, then moved to
            // the next queue.
            ("immediately1", Immediately),
            // Adding a second `Immediately` queue, to have jobs
            // executed twice, before they enter the "night" queue.
            ("immediately2", Immediately),
            // "local naive time" is a time without date that matches
            // every day, in the local time zone. Jobs in such a queue
            // are run in the given time window, only. When the time
            // window is entered, the `stop_start` command is run with
            // an additional `stop` argument, when the window ends or
            // all jobs are finished, it is run with `start`.
            ("night", LocalNaiveTimeWindow(
                stop_start: Some([
                    "sudo",
		    "/opt/silo-benchmark-ci/root/other-activity"
                ]),
                repeatedly: true,
                move_when_time_window_ends: true,
                from: "23:00",
                to: "5:30",
            )),
            // Adding a second queue with the same `stop_start` action
            // (it will not be re-executed, instead the status is
            // carried over), a little later so that the above queue
            // is started (and finished) first, but otherwise using
            // the same time window; it catches the jobs that aren't
            // finished in the "night" queue above, and then on days
            // when the "night" queue finishes early, this queue of
            // stragglers will be run; since it is configured to *not*
            // `move_when_time_window_ends`, jobs remain in here
            // forever, until done.
            ("night-stragglers", LocalNaiveTimeWindow(
                stop_start: Some([
                    "sudo",
		    "/opt/silo-benchmark-ci/root/other-activity"
                ]),
                repeatedly: true,
                move_when_time_window_ends: false,
                from: "23:10",
                to: "5:30",
            )),
            // `GraveYard` queues do not run their jobs, meaning jobs
            // that are moved here stay forever; this is meant as a
            // debugging/verification tool for spill overs (omitting
            // this last queue would get them deleted instead; but
            // then with "night-stragglers" never actually moving its
            // jobs out, this is never going to be used; leaving it
            // here in case future config changes could make use of
            // it)
            ("left-over", GraveYard),
        ],

        // Where jobs go when they run out of error_budget (`None`
        // would get them deleted instead)
        erroneous_jobs_queue: Some(
            ("erroneous-jobs", GraveYard)
        ),
    ),

    working_directory_pool: (
        // base_dir: Some("other/path/than/home/.evobench-run/working_directory_pool/"),

        // Smaller: less disk space use for build dirs, but less
        // chance to re-use a build with the same commit id without
        // having to rebuild
        capacity: 16,
    ),

    remote_repository: (
        // For server use:
        url: "https://github.com/GenSpectrum/LAPIS-SILO/",

        // For the `poll` subcommand:
        remote_branch_names: [
            "main",
        ]
    ),

    // A list of *all* environment variables your benchmarking process
    // can take, with a boolean that says whether they are also
    // *required* (do *not* list the environment variables which the
    // evobench daemon passes anyway (i.e. are not custom):
    // "COMMIT_ID", "EVOBENCH_LOG", "BENCH_OUTPUT_LOG")
    custom_parameters_required: {
        "SORTED": true,
        "RANDOMIZED": true,
        "BENCHMARK_DATASET_NAME": true,
    },

    // Each `CustomParameters` group is used for a separate benchmark
    // run for each commit it.
    custom_parameters_set: CustomParametersSet([
        CustomParameters({
            "SORTED": "1",
            "RANDOMIZED": "1",
            "BENCHMARK_DATASET_NAME": "full",
        }),
        CustomParameters({
            "SORTED": "0",
            "RANDOMIZED": "1",
            "BENCHMARK_DATASET_NAME": "full",
        }),
    ]),

    // Each job receives a copy of these settings
    benchmarking_job_settings: BenchmarkingJobSettings(
        // How many times to run the same benchmarking job across all
        // queues (higher: better statistics, at higher computing
        // cost); default: 5
        count: Some(5),
        // How many times the job can fail before it is moved to the
        // `erroneous_jobs_queue` (or dropped if that is `None`); you
        // want to use 1 for interactive use, 2-3 for CI use. default:
        // 3
        error_budget: Some(2)
    ),

    // What command to run on the target project to execute a
    // benchmarking run; the env variables configured in
    // CustomParameters are set when running this command.
    benchmarking_command: BenchmarkingCommand(
        // Relative path to the subdirectory (provide "." for the top
        // level of the working directory) where to run the command
        subdir: "benchmarking",
        command: "make",
        arguments: ["bench"],
    ),

    /// The base of the directory hierarchy where the output files
    /// should be placed
    output_base_dir: "~/silo-benchmark-outputs",
)
