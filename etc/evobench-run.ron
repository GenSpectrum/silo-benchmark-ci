// More docs may be available in the evobench source code, start with
// `struct RunConfigOpts` in
// `evobench-evaluator/src/run/config.rs`. (Note that in the source
// code, many of the types have "Opts" appended to the names used
// here, and are then converted to the type with the name without this
// suffix while checking the configuration.)

RunConfig(
    queues: (
        // run_queues_basedir: Some("other/path/than/home/.evobench-run/queues/"),

        // List of queues each job goes through in order--each entry
        // being a tuple of subdirectory name (under
        // `~/.evobench-run/queues/` by default) and scheduling
        // configuration. Jobs are inserted (via `evobench-run
        // insert`, `evobench-run insert-local`, `evobench-run poll`)
        // into the first queue configured here, then may be moved to
        // the next, depending on the scheduling configuration.
        pipeline: [
            // Scheduling type `Immediately` means that jobs are
            // picked up ASAP, i.e. immediately after a job that
            // started processing is finished. Jobs of this scheduling
            // type are run exactly once, then moved to the next
            // queue. The `situation` parameter is used to group
            // results into "summary-.."  files; we have two here,
            // those outside the night period (really just
            // "immediate"), which run without disabling other
            // activity on the server. And then further down, the
            // "night" one with other activity disabled. It's those
            // two situations we want to compare statistically.
            ("immediately1", Immediately(situation: "immediate")),
            // Adding another/more `Immediately` queue(s), to have
            // jobs executed as many times (once per each queue)
            // before they enter the "night" queue.
            ("immediately2", Immediately(situation: "immediate")),
            ("immediately3", Immediately(situation: "immediate")),
            ("immediately4", Immediately(situation: "immediate")),
            ("immediately5", Immediately(situation: "immediate")),
            // "local naive time" is a time without date that matches
            // every day, in the local time zone. Jobs in such a queue
            // are started during the given time window, only. When
            // the time window is entered, the `stop_start` command is
            // run with an additional `stop` argument, when the window
            // is exited (the time period ends or no jobs are left),
            // it is run with `start`.
            ("night", LocalNaiveTimeWindow(
                priority: Some(0),
                situation: "night",
                stop_start: Some([
                    "sudo",
                    "/opt/silo-benchmark-ci/root/other-activity"
                ]),
                repeatedly: true,
                move_when_time_window_ends: false,
                from: "23:00",
                to: "6:30",
            )),
            // Adding a second queue with the same `stop_start` action
            // (it will not be re-executed, instead the status is
            // carried over), the same time window, but with lower
            // priority; it catches the jobs that didn't manage to run
            // in the higher-priority "night" queue above (i.e. in the
            // first night after their insertion), but then on days
            // when the "night" queue finishes early, this queue of
            // stragglers still allows them to run; since it is
            // configured to *not* `move_when_time_window_ends`, jobs
            // remain in here forever, until done.
            // -- commented out since due to a bug jobs from "night" are never moved
            // ("night-stragglers", LocalNaiveTimeWindow(
            //     priority: Some(-1),
            //     situation: "night",
            //     stop_start: Some([
            //         "sudo",
            //         "/opt/silo-benchmark-ci/root/other-activity"
            //     ]),
            //     repeatedly: true,
            //     move_when_time_window_ends: false,
            //     from: "23:00",
            //     to: "5:30",
            // )),
            // `Inactive` queues do not run their jobs, meaning jobs
            // that are moved here stay forever; this is meant as a
            // debugging/verification tool for spill overs (omitting
            // this last queue would get them deleted instead; but
            // then with "night-stragglers" never actually moving its
            // jobs out, this is never going to be used; but leaving
            // it here in case future config edits change this)
            // ("unfinished", Inactive),
        ],

        // Where jobs go when they run out of error_budget (`None`
        // would get them deleted instead)
        erroneous_jobs_queue: Some(
            ("erroneous-jobs", Inactive)
        ),

        // Where jobs go when they are finished successfully (if
        // `None` is given, the jobs will be dropped--silently unless
        // verbose flag is given).
        done_jobs_queue: Some(
            ("done", Inactive)
        ),

        // How many jobs to show in the extra queues
        // (`erroneous_jobs_queue` and `done_jobs_queue`) when no
        // `--all` option is given
        view_jobs_max_len: 8,
    ),

    // The path to the directory that job runners (`evobench-run run
    // ...`) lock (with error when taken), and for additional files
    // specific for that instance. By default,
    // `~/.evobench-run/run_jobs_instance`.
    run_jobs_instance_path: None,

    working_directory_pool: (
        // base_dir: Some("other/path/than/home/.evobench-run/working_directory_pool/"),

        // Smaller: less disk space use for build dirs, but less
        // chance to re-use a build with the same commit id without
        // having to rebuild
        capacity: 12,

        // To enable working directory auto-cleaning, give the
        // cleaning options. Currently "cleaning" just means full
        // deletion by the runner with no involvement of the target
        // project.
        auto_clean: Some((
            // The minimum age a working directory should reach before
            // possibly being deleted, in days (recommended: 3)
            min_age_days: 3,

            // The minimum number of jobs that should be run in a
            // working directory before that is possibly being
            // deleted. Currently, directories are always deleted when
            // they reach both the `min_age_days` and `min_num_runs`
            // numbers. (40 might a good number to allow for a fresh
            // working directory to be used if 4 jobs * 10 runs are
            // configured. Then it's going to be deleted right after
            // those. Bad luck if it started with a partically used
            // directory (has to run preprocessing twice).)
            min_num_runs: 40,

            // If true, directories are not deleted when any job for the same
            // commit id is in the queue.  (Directories are deleted when they
            // reach both the `min_age_days` and `min_num_runs` numbers, and
            // this is false, or the current job just ended and no others for
            // the commit id exist.)
            wait_until_commit_done: true,
        ))
    ),

    // Targets are identified by `benchmarking_command.target_name`,
    // matched to the `target_name` field in `JobTemplate` (the names
    // have no other significance). Each target specifies what command
    // to run on the target project to execute a benchmarking run, and
    // what custom environment variables are used or expected for it.
    targets: [
        BenchmarkingTarget(
            benchmarking_command: BenchmarkingCommand(
                // This name is matched to the `target_name` field in
                // `JobTemplate`, and it is used as the first path
                // segment below `output_base_dir` for storing the
                // results. It will also be shown by `evobench-run
                // list`. Note that this field is part of the
                // benchmarking key (as are the other fields here!),
                // i.e. changing `target_name` leads to potential
                // re-evaluation of a commit even if nothing else
                // changed.
                target_name: "api",
                // Relative path to the subdirectory (provide "." for the top
                // level of the working directory) where to run the command
                subdir: "benchmarking",
                command: "make",
                arguments: ["api"],
            ),
            // Which custom environment variables are allowed by this
            // target, whether required, and of what type (format)
            // they must be (valid types are Filename, Dirname, Bool,
            // NonZeroU32, U32, and String (which means anything is
            // allowed)). Do not list the environment variables which
            // the evobench daemon passes anyway (i.e. are not custom:
            // "COMMIT_ID", "EVOBENCH_LOG", "BENCH_OUTPUT_LOG";
            // evobench refuses them at load time).
            allowed_custom_parameters: {
                // subdirectory name under ~/silo-benchmark-datasets
                "DATASET": AllowedCustomParameter(
                    required: true,
                    type: Dirname
                ),
                // Whether to sort the input dataset
                "SORTED": AllowedCustomParameter(
                    required: true,
                    type: Bool
                ),
                // Override: alternative file name for the
                // `silo_queries.json` file
                "QUERIES": AllowedCustomParameter(
                    required: false,
                    type: Filename
                ),

                // For api-query:

                // How many queries (connections) to run in parallel
                "CONCURRENCY": AllowedCustomParameter(
                    required: true,
                    type: NonZeroU32,
                ),
                // Whether to randomize (shuffle) the order of
                // the queries
                "RANDOMIZED": AllowedCustomParameter(
                    required: true,
                    type: Bool,
                ),
                // How many times to repeat the queries (randomizing the order
                // happens after repetition)
                "REPEAT": AllowedCustomParameter(
                    required: true,
                    type: NonZeroU32,
                ),

                // Environment variables read directly by SILO:

                "SILO_API_THREADS_FOR_HTTP_CONNECTIONS": AllowedCustomParameter(
                    required: false,
                    type: NonZeroU32,
                ),
            },
            // Optional list of `LogExtract` declarations, to extract
            // time spans from the stdout/stderr of the benchmark
            // run. (Note: this is not and does not include the file
            // optionally written by the target application to the
            // path in the `BENCH_OUTPUT_LOG` env var!--Possible todo:
            // offer something separate for that file?)
            log_extracts: Some([
                LogExtract(
                    filename: "api-query-total-seconds.txt",
                    regex_start: "api-query iter",
                    regex_end: "successes",
                ),
            ])
        ),
        // For docs see the entry above
        BenchmarkingTarget(
            benchmarking_command: BenchmarkingCommand(
                target_name: "preprocessing",
                subdir: "benchmarking",
                command: "make",
                arguments: ["preprocessing"],
            ),
            allowed_custom_parameters: {
                // subdirectory name under ~/silo-benchmark-datasets
                "DATASET": AllowedCustomParameter(
                    required: true,
                    type: Dirname
                ),
                // Whether to sort the input dataset
                "SORTED": AllowedCustomParameter(
                    required: true,
                    type: Bool
                ),
            },
        )
    ],

    // A set of named job template lists, referred to by name from
    // `job_templates_for_insert` and `remote_branch_names_for_poll`.
    // Each job template in a list generates a separate benchmark run
    // for each commit that is inserted. The order defines in which
    // order the jobs are inserted (which means the job generated from
    // the first template is scheduled first, at least if priorities
    // are the same). `priority` is added to whatever priority the
    // inserter asks for, and `initial_boost` is added to the job for
    // its first run only.
    job_template_lists: {
        "main_templates": [
            // For the "west_nile" dataset, we collect preprocessing
            // information.

            // We want the jobs from this "preprocessing" template to
            // run before those from the next one ("api" sibling), so
            // we put it here first; that way it is inserted into the
            // pipeline first, ensuring that if the daemon races us,
            // it is picked up before the other job is added (a higher
            // priority wouldn't help in this case). The reason we
            // want it to run first is so that the "api" job can just
            // re-use the result of this "preprocessing" job, avoiding
            // the need for the "api" job to run the preprocessing on
            // its own (which it would do without data capture), hence
            // saving one preprocessing run.
            JobTemplate(
                priority: -1,
                // make initial total priority at least as high (-1 +
                // 2 >= 1) as the "api" sibling's below
                initial_boost: 2,
                target_name: "preprocessing",
                custom_parameters: {
                    "DATASET": "west_nile",
                    "SORTED": "0",
                },
            ),
            JobTemplate(
                priority: 1,
                initial_boost: "normal",
                target_name: "api",
                custom_parameters: {
                    "CONCURRENCY": "120",
                    "DATASET": "west_nile",
                    "RANDOMIZED": "1",
                    "REPEAT": "5",
                    "SORTED": "0",
                },
            ),

            // For the "SC2open" dataset, we do not collect preprocessing
            // information because it would be too much data. Let the
            // "api" target run the preprocessing itself (without
            // capturing benchmarking information).

            // JobTemplate(
            //     priority: "normal",
            //     initial_boost: "normal",
            //     target_name: "api",
            //     custom_parameters: {
            //         "CONCURRENCY": "120",
            //         "DATASET": "SC2open",
            //         "RANDOMIZED": "1",
            //         "REPEAT": "1",
            //         "SORTED": "1",
            //     },
            // ),
            JobTemplate(
                priority: "normal",
                initial_boost: "normal",
                target_name: "api",
                custom_parameters: {
                    "CONCURRENCY": "120",
                    "DATASET": "SC2open",
                    "RANDOMIZED": "1",
                    "REPEAT": "1",
                    "SORTED": "0",
                },
            ),
            JobTemplate(
                priority: "normal",
                initial_boost: "normal",
                target_name: "api",
                custom_parameters: {
                    "CONCURRENCY": "120",
                    "DATASET": "SC2open",
                    "RANDOMIZED": "1",
                    "REPEAT": "1",
                    "SILO_API_THREADS_FOR_HTTP_CONNECTIONS": "16",
                    "SORTED": "0",
                },
            ),
        ],
        "bench_branch_templates": [
            JobTemplate(
                priority: 1.25,
                initial_boost: "normal",
                target_name: "api",
                custom_parameters: {
                    "CONCURRENCY": "120",
                    "DATASET": "west_nile",
                    "RANDOMIZED": "1",
                    "REPEAT": "5",
                    "SORTED": "0",
                },
            ),
        ],
        "bench_branch_templates_sc2open": [
            // JobTemplate(
            //     priority: 1.1,
            //     initial_boost: "normal",
            //     target_name: "api",
            //     custom_parameters: {
            //         "CONCURRENCY": "120",
            //         "DATASET": "SC2open",
            //         "RANDOMIZED": "1",
            //         "REPEAT": "1",
            //         "SORTED": "1",
            //     },
            // ),
            JobTemplate(
                priority: 1.1,
                initial_boost: "normal",
                target_name: "api",
                custom_parameters: {
                    "CONCURRENCY": "120",
                    "DATASET": "SC2open",
                    "RANDOMIZED": "1",
                    "REPEAT": "1",
                    "SORTED": "0",
                },
            ),
            JobTemplate(
                priority: 1.1,
                initial_boost: "normal",
                target_name: "api",
                custom_parameters: {
                    "CONCURRENCY": "120",
                    "DATASET": "SC2open",
                    "RANDOMIZED": "1",
                    "REPEAT": "1",
                    "SILO_API_THREADS_FOR_HTTP_CONNECTIONS": "16",
                    "SORTED": "0",
                },
            ),
        ],
        "bench_branch_templates_prepr": [
            JobTemplate(
                priority: 1.2,
                initial_boost: 1,
                target_name: "preprocessing",
                custom_parameters: {
                    "DATASET": "west_nile",
                    "SORTED": "0",
                },
            ),
        ],
        "bench_branch_templates_sc2openp": [
            JobTemplate(
                priority: 1.05,
                initial_boost: 0.1,
                target_name: "preprocessing",
                custom_parameters: {
                    "DATASET": "SC2open",
                    "SORTED": "0",
                },
            ),
        ],
    },

    // Job templates for using the "evobench-run insert" or
    // "insert-local" sub-commands. Reference into
    // `job_template_lists` via `Ref("..")`, or provide a list of
    // JobTemplate entries directly via `Val([..])`.
    job_templates_for_insert: Ref("main_templates"),

    remote_repository: (
        // The url to clone from
        url: "https://github.com/GenSpectrum/LAPIS-SILO/",

        // Branches which should be checked by the `poll` subcommand,
        // and what job templates should be used to insert jobs for
        // commits from the branch; use `Ref(..)` to refer to one of
        // the names in `job_template_lists`, or `Val([..])` to
        // provide a JobTemplate list directly.
        remote_branch_names_for_poll: {
            "main": Ref("main_templates"),

            "bench_alexander": Ref("bench_branch_templates"),
            "bench_anna": Ref("bench_branch_templates"),
            "bench_chaoran": Ref("bench_branch_templates"),
            "bench_christian": Ref("bench_branch_templates"),
            "bench_fabian": Ref("bench_branch_templates"),

            "bench_alexander_sc2open": Ref("bench_branch_templates_sc2open"),
            "bench_anna_sc2open": Ref("bench_branch_templates_sc2open"),
            "bench_chaoran_sc2open": Ref("bench_branch_templates_sc2open"),
            "bench_christian_sc2open": Ref("bench_branch_templates_sc2open"),
            "bench_fabian_sc2open": Ref("bench_branch_templates_sc2open"),

            "bench_alexander_prepr": Ref("bench_branch_templates_prepr"),
            "bench_anna_prepr": Ref("bench_branch_templates_prepr"),
            "bench_chaoran_prepr": Ref("bench_branch_templates_prepr"),
            "bench_christian_prepr": Ref("bench_branch_templates_prepr"),
            "bench_fabian_prepr": Ref("bench_branch_templates_prepr"),

            "bench_alexander_sc2openp": Ref("bench_branch_templates_sc2openp"),
            "bench_anna_sc2openp": Ref("bench_branch_templates_sc2openp"),
            "bench_chaoran_sc2openp": Ref("bench_branch_templates_sc2openp"),
            "bench_christian_sc2openp": Ref("bench_branch_templates_sc2openp"),
            "bench_fabian_sc2openp": Ref("bench_branch_templates_sc2openp"),

            // Example for ad-hoc templates:
            "bench_alexander_adhoc": Val([
                JobTemplate(
                    priority: 1.25,
                    initial_boost: "normal",
                    target_name: "api",
                    custom_parameters: {
                        "CONCURRENCY": "120",
                        "DATASET": "west_nile",
                        "RANDOMIZED": "1",
                        "REPEAT": "5",
                        "SORTED": "0",
                    },
                ),
            ]),
        }
    ),

    // Each job receives a copy of these settings
    benchmarking_job_settings: BenchmarkingJobSettings(
        // How many times to run the same benchmarking job across all
        // queues (higher: better statistics, at higher computing
        // cost, although, thanks to the re-use of working
        // directories, subsequent runs can be cheap compared to the
        // first one); default: 5
        count: Some(10),
        // After how many failures the job is moved to the
        // `erroneous_jobs_queue` (or dropped if that is `None`); you
        // want to use 1 for interactive use, 2-3 for CI use. default:
        // 3 (i.e. 2 failures are the maximum to still allow the job
        // to finish)
        error_budget: Some(2)
    ),
    
    /// The base of the directory hierarchy where the output files
    /// should be placed
    output_base_dir: "~/silo-benchmark-outputs",

    /// Optional directory holding directories whose name is taken
    /// from the (optional, depending on the configuration) `DATASET`
    /// custom variable (hacky to mis-use a custom variable for
    /// this?), inside which are directories named after git revision
    /// names (tags or commit ids), the latest which is an ancestor or
    /// the commit itself to be benchmarked,
    /// i.e. `$versioned_datasets_base_dir/$DATASET/$best_rev_name`. The
    /// resolved path (only when both this option and `DATASET` are
    /// provided) is stored in the `DATASET_DIR` env var when calling
    /// the benchmarking entry point of the client app.
    versioned_datasets_base_dir: Some("~/silo-benchmark-datasets"),
)
